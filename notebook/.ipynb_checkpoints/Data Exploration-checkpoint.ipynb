{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "harukiDf = pd.read_csv(\"../dataset/Haruki-Murakami-th.csv\",header=None)\n",
    "kafKaDf = pd.read_csv(\"../dataset/Kafka-Murakami-th.csv\",header=None)\n",
    "norwegianDf = pd.read_csv(\"../dataset/Norwegian-Murakami-th.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hauriki Number of tweets: 1073\n",
      "Kafka Number of tweets: 11\n",
      "Norwegian Number of tweets: 165\n"
     ]
    }
   ],
   "source": [
    "print(\"Haruki Number of tweets: %d\"%harukiDf.shape[0])\n",
    "print(\"Kafka Number of tweets: %d\"%kafKaDf.shape[0])\n",
    "print(\"Norwegian Number of tweets: %d\"%norwegianDf.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Haruki Number of unique tweets: 29\n",
      "Kafka Number of unique tweets: 5\n",
      "Norwegian Number of unique tweets: 21\n"
     ]
    }
   ],
   "source": [
    "print(\"Haruki Number of unique tweets: %d\"%harukiDf[2].unique().shape[0])\n",
    "print(\"Kafka Number of unique tweets: %d\"%kafKaDf[2].unique().shape[0])\n",
    "print(\"Norwegian Number of unique tweets: %d\"%norwegianDf[2].unique().shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate data to form one big array of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([harukiDf,kafKaDf,norwegianDf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def cleanText(text):\n",
    "    stopwords = ['\\r\\n','RT']\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    for stopword in stopwords:\n",
    "        text = text.replace(stopword,'')\n",
    "    \n",
    "    return text\n",
    "df[2] = df[2].apply(cleanText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 34s, sys: 8.27 s, total: 3min 42s\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import deepcut as dc\n",
    "df['tokenized'] = df[2].apply(dc.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"../dataset/combined_tokenized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = df['tokenized'].values\n",
    "#tweets = df['tokenized'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1249,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ [' ', '@', 'CandideBooks', ':', ' ', 'สวัสดี', 'วัน', 'หยุด', ' ', 'ฟัง', 'เพลง', 'จาก', 'แผ่น', 'ไวนิล', 'ส่วน', 'ตัว', 'ของ', 'มูราคา', 'มิ', 'กัน', 'ค่ะ', ' ', 'เพลง', 'เหล่า', 'นี้', 'ไป', 'ปรากฏ', 'ใน', 'หนังสือ', 'ของ', 'เขา', 'หลาย', 'เล่ม', 'เลย', ' '],\n",
       "       [' ', '@', 'CandideBooks', ':', ' ', 'สวัสดี', 'วัน', 'หยุด', ' ', 'ฟัง', 'เพลง', 'จาก', 'แผ่น', 'ไวนิล', 'ส่วน', 'ตัว', 'ของ', 'มูราคา', 'มิ', 'กัน', 'ค่ะ', ' ', 'เพลง', 'เหล่า', 'นี้', 'ไป', 'ปรากฏ', 'ใน', 'หนังสือ', 'ของ', 'เขา', 'หลาย', 'เล่ม', 'เลย', ' '],\n",
       "       ['\"', 'อย่า', 'ได้', 'เผา', 'ชีวิต', 'ตัว', 'เอง', 'ทิ้ง', 'ไป', 'ใน', 'การ', 'ฝืนใจ', 'ทำ', '\"', ' ', '-', ' ', 'ด้วย', 'รัก', ' ', 'ความ', 'ตาย', ' ', 'หัวใจ', 'สลาย', '/', ' ', 'Haruki Murakami', ' '],\n",
       "       ...,\n",
       "       [' ', '@', 'ItsView_', ': ', '#JJProjcet', 'เก็บ', 'หนังสือ', ' ', 'norwegian', ' ', 'wood', ' ', 'ชื่อ', 'ไทย', ' ', '\"', 'ด้วย', 'รัก', ' ', 'ความ', 'ตาย', ' ', 'และ', 'หัวใจ', 'สลาย', '\"', ' ', 'เข้า', 'ลิสต์', ' ', '#แจบ', 'อม', 'อ่าน', ' ', 'อีก', 'เล่ม', 'ค่ะ', 'ปล.', 'เคย', 'เป็น', ' ', '#จิ', '…'],\n",
       "       [' ', '@Jinyoung_Books', ':', ' ', 'หนังสือ', 'ที่', 'เจบี', 'ถือ', 'อยู่', ' ', 'ฉบับ', 'แปล', 'ไทย', ' ', 'คือ', ' ', 'หนังสือ', 'ด้วย', 'รัก', ' ', 'ความ', 'ตาย', ' ', 'และ', 'หัวใจ', 'สลาย', 'ค่ะ', ' '],\n",
       "       [' ', '@', 'ItsView_', ': ', '#JJProjcet', 'เก็บ', 'หนังสือ', ' ', 'norwegian', ' ', 'wood', ' ', 'ชื่อ', 'ไทย', ' ', '\"', 'ด้วย', 'รัก', ' ', 'ความ', 'ตาย', ' ', 'และ', 'หัวใจ', 'สลาย', '\"', ' ', 'เข้า', 'ลิสต์', ' ', '#แจบ', 'อม', 'อ่าน', ' ', 'อีก', 'เล่ม', 'ค่ะ', 'ปล.', 'เคย', 'เป็น', ' ', '#จิ', '…']], dtype=object)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [' ','\"','ที่','เรา','กัน','อื่น',':','จะ','ได้','@','ว่า','_','-','ก็','เท่า','อื่น','นึง','..','ไม่','ทำ','มี','เป็น','อีก','นี้','ลืม']\n",
    "words = [word for tweet in tweets for word in tweet if word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('คิด', 1460),\n",
       " ('อ่าน', 1402),\n",
       " ('คน', 1380),\n",
       " ('หนังสือ', 827),\n",
       " ('Haruki Murakami', 789),\n",
       " ('พูด', 757),\n",
       " ('ญี่ปุ่น', 660),\n",
       " ('ถ้า', 660),\n",
       " ('คำคม', 658),\n",
       " ('อัน', 658),\n",
       " ('SaraUpdate', 657),\n",
       " ('ความ', 513),\n",
       " ('ให้', 510),\n",
       " ('วัน', 461),\n",
       " ('…', 395),\n",
       " ('และ', 371),\n",
       " ('—', 238),\n",
       " ('@readery_co', 237),\n",
       " ('ดี', 235),\n",
       " ('ไป', 177),\n",
       " ('ตาย', 171),\n",
       " ('ด้วย', 168),\n",
       " ('รัก', 168),\n",
       " ('ใน', 162),\n",
       " ('ตัว', 160),\n",
       " ('หัวใจ', 152),\n",
       " ('สลาย', 149),\n",
       " ('มัน', 148),\n",
       " ('เอง', 145),\n",
       " ('บน', 144),\n",
       " ('การ', 142),\n",
       " ('คุณ', 142),\n",
       " ('TPaperless', 141),\n",
       " ('ผม', 141),\n",
       " ('ถึง', 140),\n",
       " ('ตอน', 140),\n",
       " ('ทุก', 139),\n",
       " ('ตา', 138),\n",
       " ('รุ่ง', 138),\n",
       " ('เช้า', 138),\n",
       " ('เตียง', 138),\n",
       " ('นอน', 138),\n",
       " ('ช่วย', 138),\n",
       " ('ไขลาน', 138),\n",
       " ('เต็ม', 138),\n",
       " ('บอก', 138),\n",
       " ('กับ', 138),\n",
       " ('ที่สุด', 138),\n",
       " ('อยู่', 137),\n",
       " ('Ha', 136),\n",
       " ('แค่', 127),\n",
       " ('เรื่อง', 118),\n",
       " ('มากมาย', 108),\n",
       " (',', 107),\n",
       " ('ใด', 102),\n",
       " ('ไหน', 101),\n",
       " ('“', 101),\n",
       " ('”', 101),\n",
       " ('ไม่ว่า', 100),\n",
       " ('ขนาด', 100),\n",
       " ('เปิดใจ', 99),\n",
       " ('ตรงไปตรงมา', 99),\n",
       " ('ย่อม', 99),\n",
       " ('เปิด', 99),\n",
       " ('ปาก', 99),\n",
       " ('จาก', 98),\n",
       " ('จริง', 97),\n",
       " ('มา', 96),\n",
       " ('ค่ะ', 89),\n",
       " ('หรือ', 86),\n",
       " ('จน', 85),\n",
       " ('ปรารถนา', 84),\n",
       " ('ใจดี', 84),\n",
       " ('เยียวยา', 84),\n",
       " ('เศร้า', 84),\n",
       " ('เฝ้า', 84),\n",
       " ('มอง', 84),\n",
       " ('จบ', 84),\n",
       " ('เรียนรู้', 84),\n",
       " ('Haruki Muraka', 83),\n",
       " ('ไทย', 76),\n",
       " ('สัญญา', 70),\n",
       " ('ใคร', 66),\n",
       " ('แล้ว', 61),\n",
       " ('เคย', 60),\n",
       " ('เล่ม', 56),\n",
       " ('แต่', 55),\n",
       " ('สัก', 52),\n",
       " ('ของ', 49),\n",
       " ('norwegian', 49),\n",
       " ('wood', 49),\n",
       " ('#แจบ', 49),\n",
       " ('คือ', 43),\n",
       " ('ชื่อ', 43),\n",
       " ('เข้า', 42),\n",
       " ('ItsView_', 41),\n",
       " (': ', 41),\n",
       " ('#JJProjcet', 41),\n",
       " ('เก็บ', 41),\n",
       " ('ลิสต์', 41)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "counts = Counter(words)\n",
    "counts.most_common(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
